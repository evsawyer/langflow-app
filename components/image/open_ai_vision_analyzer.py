# Save this code as a Python file (e.g., openai_vision_component.py)
# and import it into your LangFlow project.

from langflow.custom import Component
# Using newer IO types from Langflow >= 1.0
from langflow.io import Output, SecretStrInput, StrInput, MessageTextInput
from langflow.schema import Message
from langflow.field_typing import LanguageModel # Optional, for future use if model becomes an input

import os
from openai import OpenAI, APIError, AuthenticationError, RateLimitError # Import specific errors
import logging
import asyncio # Needed for asyncio.to_thread

# Setup basic logging
logger = logging.getLogger(__name__)

class OpenAiVisionAnalyzer(Component):
    """
    Analyzes an image from a URL using an OpenAI vision model based on provided instructions.
    """
    display_name = "OpenAI Vision Analyzer"
    description = "Sends an image URL and text instructions to an OpenAI vision model (e.g., gpt-4o-mini) and returns the text response."
    documentation: str = (
        "Inputs:\n"
        "- Image URL: Publicly accessible URL of the image to analyze.\n"
        "- OpenAI API Key: Your secret OpenAI API key.\n"
        "- Instructions: Text prompt telling the model what to do with the image.\n\n"
        "Outputs:\n"
        "- OpenAI Response: The text generated by the model."
    )
    icon = "bot"
    name = "OpenAiVisionAnalyzer"

    inputs = [
        MessageTextInput(
            name="image_url",
            display_name="Image URL",
            info="Publicly accessible URL of the image (e.g., from Cloudinary).",
            required=True
        ),
        SecretStrInput(
            name="openai_api_key",
            display_name="OpenAI API Key",
            info="Your secret OpenAI API key.",
            required=True
        ),
        # Using MessageTextInput for potentially longer instructions
        MessageTextInput(
            name="instructions",
            display_name="Instructions",
            info="Text prompt telling the model what to analyze or extract from the image.",
            value="Describe this image in detail.", # Default instruction
            required=True
        ),
         StrInput(
            name="model_name",
            display_name="Model Name",
            info="The OpenAI vision model to use (e.g., gpt-4o-mini, gpt-4o, gpt-4-turbo).",
            value="gpt-4o-mini", # Default to cost-effective option
            required=True
        ),
        StrInput(
            name="max_tokens",
            display_name="Max Tokens (Optional)",
            info="Maximum number of tokens to generate in the response.",
            value="300",
            required=False,
            advanced=True # Mark as advanced option
        )
    ]

    outputs = [
        Output(display_name="OpenAI Response", name="openai_response", method="analyze_image"),
    ]

    def _run_openai_sync(self, client, model_name, messages, max_tokens_int):
        """Synchronous helper to run the API call, intended for asyncio.to_thread."""
        return client.chat.completions.create(
            model=model_name,
            messages=messages,
            max_tokens=max_tokens_int
        )

    async def analyze_image(self) -> Message:
        """
        Sends the image URL and instructions to OpenAI and returns the response.
        """
        image_url: str = self.image_url
        api_key_input: Secret = self.openai_api_key
        instructions: str = self.instructions
        model_name: str = self.model_name
        max_tokens_str: str = self.max_tokens
        output_text: str = "" # Initialize empty output

        # Handle Secret input
        actual_api_key = api_key_input if isinstance(api_key_input, str) else api_key_input.load() if api_key_input else None

        # --- Input Validation ---
        if not image_url:
            self.status = "Error: Image URL is missing."
            logger.error(self.status)
            return Message(text="")
        if not actual_api_key:
            self.status = "Error: OpenAI API Key is missing."
            logger.error(self.status)
            return Message(text="")
        if not instructions:
            self.status = "Error: Instructions are missing."
            logger.error(self.status)
            return Message(text="")
        if not model_name:
            self.status = "Error: Model Name is missing."
            logger.error(self.status)
            return Message(text="")

        # Convert max_tokens to int, handle potential errors or empty string
        try:
            max_tokens_int = int(max_tokens_str) if max_tokens_str else None
        except ValueError:
            self.status = "Warning: Invalid 'Max Tokens' value, ignoring."
            logger.warning(f"Invalid max_tokens value '{max_tokens_str}', proceeding without it.")
            max_tokens_int = None


        self.status = f"Preparing request for {model_name}..."
        logger.info(f"Sending request to OpenAI model '{model_name}' for image: {image_url}")

        try:
            # Initialize OpenAI Client
            client = OpenAI(api_key=actual_api_key)

            # Construct the messages payload for multimodal input
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": instructions
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": image_url,
                                # "detail": "auto" # Optional
                            }
                        }
                    ]
                }
            ]

            self.status = f"Sending request to {model_name}..."

            # Run the synchronous OpenAI SDK call in a separate thread
            # to avoid blocking Langflow's async event loop
            response = await asyncio.to_thread(
                self._run_openai_sync, client, model_name, messages, max_tokens_int
            )

            # Extract the response text
            if response.choices and response.choices[0].message:
                output_text = response.choices[0].message.content or "" # Ensure it's a string
                self.status = "Success: Received response from OpenAI."
                logger.info(f"OpenAI response received successfully (Length: {len(output_text)}).")
            else:
                 self.status = "Warning: OpenAI response structure unexpected or empty."
                 logger.warning(f"OpenAI response was empty or had unexpected structure: {response}")


        except AuthenticationError as auth_err:
             self.status = f"Authentication Error: Check your OpenAI API Key. ({auth_err})"
             logger.error(self.status)
        except RateLimitError as rate_err:
             self.status = f"Rate Limit Error: You may have exceeded your OpenAI quota or rate limit. ({rate_err})"
             logger.error(self.status)
        except APIError as api_err:
             # This can include model not found, invalid request, server errors etc.
             self.status = f"OpenAI API Error: {api_err}"
             logger.error(self.status)
        except Exception as e:
            self.status = f"Error: An unexpected error occurred while contacting OpenAI. {type(e).__name__}: {e}"
            logger.error(self.status, exc_info=True)

        # Return the result (or empty string on error) within a Message object
        return Message(text=output_text)
